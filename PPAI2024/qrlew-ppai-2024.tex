%File: anonymous-submission-latex-2024.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai24}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[usestackEOL]{stackengine}
\stackMath
%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2024.1)
}

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai24.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% A command for the project name
\newcommand{\qrlew}{\emph{Qrlew}}

\newcommand\coolover[2]{\mathrlap{\smash{\overbrace{\phantom{%
    \begin{matrix} #2 \end{matrix}}}^{\mbox{$#1$}}}}#2}

\newcommand\coolrightbrace[2]{%
\left.\vphantom{\begin{matrix} #1 \end{matrix}}\right\}#2}

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{\qrlew: Differentially Privacte SQL Query Rewriting}
\author{
    %Authors
    % Authors
    Nicolas Grislain\textsuperscript{\rm 1}
    Paul Roussel\textsuperscript{\rm 1}
    Victoria de Sainte Agathe\textsuperscript{\rm 1}
}
\affiliations{
    %Afiliations
    \textsuperscript{\rm 1}Sarus Technologies\\
    % If you have multiple authors and multiple affiliations
    % use superscripts in text and roman font to identify them.
    % For example,

    % Sunil Issar\textsuperscript{\rm 2},
    % J. Scott Penberthy\textsuperscript{\rm 3},
    % George Ferguson\textsuperscript{\rm 4},
    % Hans Guesgen\textsuperscript{\rm 5}
    % Note that the comma should be placed after the superscript

    1900 Embarcadero Road, Suite 101\\
    Palo Alto, California 94303-3310 USA\\
    % email address must be in roman text type, not monospace or sans serif
    proceedings-questions@aaai.org
%
% See more examples next
}

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{\qrlew: automatic differential privacy for SQL queries}
\author {
    % Authors
    Nicolas Grislain,
    Paul Roussel,
    Victoria de Sainte Agathe,
}
\affiliations {
    % Affiliations
    ng@sarus.tech, pr@sarus.tech, vdsa@sarus.tech
}
\fi

\begin{document}

\maketitle

\begin{abstract}
In this paper we introduce \qrlew{}, an \emph{open source} library that can parse SQL queries into \emph{Relations} --- an intermediate representation --- that keep track of rich data-types, value ranges and row ownership, so that they can easily be rewritten into \emph{differentially-private} equivalent and turned back into SQL queries for execution in a standard data-store with virtually no technical integration.

With \qrlew{}, a \emph{data practitionner} can express his data queries in standard SQL; the \emph{data owner} can run the rewritten query without any technical intergration and strong privacy garantees; and the query rewriting can be operated by a privacy-expert that has to be trusted by the owner, but may belong to a separate organizations.
\end{abstract}

\section{Introduction}

In recent years, the importance of safeguarding privacy when dealing with personal data has continuously increased.
Traditional anonymization techniques have proven vulnerable to re-identification, as demonstrated by numerous works \cite{archie2018s, dwork2017exposed, narayanan2008robust, sweeney2013identifying}.
The total cost of data breaches has also significantly increased \cite{ibm2023cost} and governments have introduced stricter data protection laws.
Yet, the collection, sharing, and utilization of data hold the potential to generate significant value across various industries, including healthcare, finance, transportation, and energy distribution.

To realize these benefits while managing privacy risks, researchers have turned to \emph{differential privacy (DP)} \cite{wood2018differential, dwork2014algorithmic}, which has become the \emph{gold standard} for privacy protection since its introduction by Dwork et al. in 2006 \cite{dwork2006calibrating} due to its provable and automatic privacy guarantees.

Despite the availability of open-source tools, DP adoption remained limited.
One of the reasons for this lack of adoption is the relative complexity of the existing tools considered the utility of the results.
\qrlew{} \cite{Grislain_Qrlew_2023} has been designed to solve these problems by providing the following features:
\begin{description}
    \item[\qrlew{} provides automatic output privacy guarantees]
    With \qrlew{} a \emph{data owner} can let an analyst (\emph{data practitionner}) with no expertise in privacy protection run arbitrary SQL queries with strong privacy garantees on the output.
    \item[\qrlew{} leverages existing infrastructures]
    \qrlew{} rewrites a SQL query into a \emph{differentially private} SQL query that can be run on any data-store with a SQL interface: from lightweight DB to big-data stores.
This removes the need for a custom execution engine and enables \emph{differentially private analytics with virtually no technical integration}.
    \item[\qrlew{} leverages synthetic data]
    Synthetic data are an increasingly popular way of \emph{privatizing} a dataset. Using jointly: \emph{differentially private} mechanisms and \emph{differentially private} synthetic data can be a simple, yet powerful, way of managing a privacy budget and reaching better utility-privacy tradeoffs.
\end{description}

% Motivation DP
% Solutions existantes
% Problème non résolu et nécessité de \qrlew

% à développer plus:
% - adaptativité -> utiliser output DP pour tuner DP aval
% - More mechanisms
% - Interconnectivité

\section{Assumptions and Design Goals}

In this work, we assume the \emph{central model of differential privacy} \cite{near2020threat}, where a trusted central organization: hospital, insurance company, utility provider, called the \emph{data owner}, collects and stores personal data in a secure database and whishes to let untrusted \emph{data practitionners} run SQL queries on its data.

At a high level we pursued the following requirements:
\begin{itemize}
    \item Ease of use for the \emph{data practitionners}. The \emph{data practitionners} are assumed to be a data experts but no privacy experts. They should be able to express their queries in a standard way. We chose SQL as the query language as it is very commonly used for analytics tasks.
    \item Ease of integration for the \emph{data owner}. As SQL is a common language to express data analysis tasks, many data-stores support it from small embedded databases to big data stores.
    \item Simplicity for the \emph{data owner} to setup privacy protection. Differential privacy is about capping the sensitivity of a result to the addition or removal of an individual that we call \emph{protected entity}. \qrlew{} assumes that the \emph{data owner} can tell if a table is public and, if it is not, that it can assign exactly one \emph{protected entity} to each row of data. In the case there are multiple related tables, \qrlew enables to define easily the \emph{protected entities} for each tables transitively.
    \item Simple integration with other privacy enhancing technologies such as \emph{synthetic data}. To avoid repeated privacy losses or give result when a DP rewriting is not easily available (e.g. when the query is: \texttt{SELECT * FROM table}) \qrlew can use \emph{synthetic data} to blend in the computation.
\end{itemize}

To minimize 
The rewriting process 

Furthermore, the
\qrlew{} was designed to ease the

\section{General architecture}

\begin{figure*}[t]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/Qrlew - process.pdf} % Reduce the figure size so that it is slightly narrower than the column.
    \caption{Caption.}
    \label{process}
    \end{figure*}

\begin{description}
    \item[Parsing into Relation]

    \item[Rewriting]
Rewriting in \qrlew{}, as detailed in Section~\ref{sec:rewriting_algorithm}, refers to the process of altering parts of a \emph{Relation} by substituting them with different components to alter the privacy properties of the result. This substitution aims to achieve specific objectives, such as ensuring privacy through the incorporation of differential privacy mechanisms. To facilitate this work, we decompose the SQL query in the form of a computation graph where each node (a \texttt{Relation}) is the result of transformations representing part of the SQL queries.

The main goals of the differential privacy rewriting are to modify SQL queries to ensure compliance with differential privacy frameworks, protecting sensitive data, and to guarantee that these modifications are consistent and deterministic, adhering to established privacy standards.

The challenge lies in accurately identifying sections for modification across a complex array of potential transformations, vigilantly tracking the integrity of data rows tied to protected entities during extensive aggregations, and adeptly applying the correct rewriting rules tailored to the relation dynamics of the query, such as Joins, Maps, or Reduces, while considering the original configuration of the sensitive data.

    \item[Rewriting]
\end{description}

\subsection{Qrlew Intermediate Representation}

\subsection{Range Propagation}

\subsection{Protected Entity Definition}

\subsection{Query Rewriting}


\input{rewriting.tex}

\section{Privacy algorithms}
\label{sec:privacy_algos}

At this stage, we examine a \texttt{Relation} that takes one or two protected \texttt{Relation} inputs, where the entity to be protected is specified.
To secure the outcome of the SQL query, it is imperative to protect not only the results obtained from aggregation functions but also the grouping keys.
We will briefly describe these two steps in the following section.

\subsubsection{Protecting aggregation results}

The protection of aggregation functions is carried out in three sequential steps. Given that all currently supported aggregations (\texttt{COUNT}, \texttt{SUM}, \texttt{AVG}, \texttt{VARIANCE} \texttt{STDDEV}) can be expressed as compositions of sums, our focus will be on the \texttt{SUM} aggregation. Let's consider the scenario where we aim to compute the sum of a column.

\begin{enumerate}
	\item \textbf{Limit the contribution per user within groups}:
	We represent the contribution of each user by a vector whose each component is the sum of the contributions within one group
    then we calculate its $\ell_2$ norm.
    Subsequently, we constrain the contributions of a specific user by scaling $\textbf{x}$ with a factor chosen to maintain the original observations if the $\ell_2$ norm of the user's observations does not exceed the clipping factor $c$.
    Conversely, if the $\ell_2$ norm surpasses $c$, the $\ell_2$  norm of the rescaled observations is restricted to $c$.
    More technical details can be found in the appendix \ref{sec:limit_contrib_per_user}.

	\item \textbf{Add random noise}:
	The sum of the original data is substituted with the sum of the scaled data with the addition of Gaussian noise. The level of noise is parameterized by the clipping and privacy parameters.

	\item \textbf{Restrict differentially private aggregation}:
	The final operation involves confining the differentially private aggregation within the bounds automatically computed for the $\text{\texttt{SUM}}(\textbf{x})$.
\end{enumerate}

\subsubsection{Protecting grouping keys}
As explained by \citeauthor{wilson2019differentially}, making grouping keys public could result in privacy breaches.
The treatment of grouping keys varies depending on whether the analyst knows them.

\begin{itemize}
	\item \textbf{Public Grouping Keys.}We categorize grouping keys as public when the analyst specifies them in the \texttt{WHERE} clause.
	In this scenario, all user-specified keys must be disclosed, even if they do not exist in the database.
	If a key is absent in the database, differentially private results will include these missing keys, and the corresponding aggregations will be random noise.
	\item \textbf{Revealing Private Keys through $\tau$-Thresholding}
	As introduced by \citeauthor{wilson2019differentially}, tau-thresholding involves releasing keys whose differentially private noise surpasses a threshold determined by privacy parameters.
\end{itemize}

When the SQL query involves both public and private grouping keys, we perform cross joins on the grouping keys obtained through the two algorithms.

\section{Comparison to other systems}

The Google differential-privacy extension for ZetaSQL enables differentially private analysis through SQL tools.
Users can incorporate privacy guarantees by including a privacy clause in their queries, which replaces aggregations with their differentially private equivalent,
limits the number of grouping keys per user, and applies tau-thresholding.
While this framework does not support complex queries with joins or inner subqueries,
it offers a straightforward integration with SQL databases.

Smartnoise SQL is a Python framework, built on the top of Open-DP, for doing SQL analysis with differential privacy guarantees.
The framework is easy of use for non-experts, but it does not support all SQL grammar, and complex queries with joins or subqueries are not supported.
Additionally, the execution of SQL analysis requires a Python post-processing step,
potentially leading to increased execution times.

OpenDP is a Rust library with Python bidings designed for building SQL-like transformations with differential privacy guarantees.
Each part of the code is well documented with mathematical proofs but
its utilization can be challenging for for non experts.

Similarly, Tumult Analytics does not directly handle SQL queries; instead, it utilizes transformations that closely resemble SQL syntax.
While offering support for budgeting various privacy tasks, it is important to note that the analysis must be executed by the data owner.

Chorus is the closest framework to \qrlew, and in the work by \citeauthor{johnson2020chorus},
there is a strong emphasis on conducting all analyses directly within the database.
However, it's worth noting that the code for Chorus is no longer being actively maintained.



\section{Known limitations}

\qrlew{} relies on the random number generator of the SQL engine used. It is usually not a cryptographic noise.

\qrlew{} uses the floating-point numbers of the host SQL engine, therefore our system is liable to the vulnerabilities described in \citeauthor{casacuberta2022widespread}.


\section*{Useful links}
\subsection{PPAI}
Last year papers:
\url{https://aaai-ppai23.github.io/#sp2}
This year program:
\url{https://ppai-workshop.github.io/}

\subsection{Comparable open-source projects}

\begin{itemize}
    \item Paszke et al. 2017 - Automatic differentiation in PyTorch \url{https://openreview.net/pdf?id=BJJsrmfCZ}
    \item Frostig et al. 2018 - Compiling machine learning programs via high-level tracing \url{https://mlsys.org/Conferences/2019/doc/2018/146.pdf}
\end{itemize}

\subsection{Comparable DP SQL papers}

\begin{itemize}
    \item Lessons Learned: Surveying the Practicality of Differential Privacy in the Industry \cite{garrido2022lessons}
    \item Tumult Analytics: a robust, easy-to-use, scalable, and expressive framework for differential privacy \cite{berghel2022tumult}
    \item Differentially Private SQL with Bounded User Contribution \cite{wilson2019differentially}
    \item CHORUS: a Programming Framework for Building Scalable Differential Privacy Mechanisms \cite{johnson2020chorus}
    \item Towards Practical Differential Privacy for SQL Queries \cite{johnson2018towards}
\end{itemize}

\bigskip
\noindent Thank you for reading these instructions carefully. We look forward to receiving your electronic files!

% \bibliography{aaai24}
\bibliography{qrlew}
\appendix

\section*{Appendix}

\input{annex.tex}

\end{document}
