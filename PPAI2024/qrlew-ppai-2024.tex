%File: anonymous-submission-latex-2024.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai24}  % DO NOT CHANGE THIS
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage[usestackEOL]{stackengine}
\stackMath
%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2024.1)
}

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai24.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% A command for the project name
\newcommand{\qrlew}{\emph{Qrlew}}

\newcommand\coolover[2]{\mathrlap{\smash{\overbrace{\phantom{%
    \begin{matrix} #2 \end{matrix}}}^{\mbox{$#1$}}}}#2}

\newcommand\coolrightbrace[2]{%
\left.\vphantom{\begin{matrix} #1 \end{matrix}}\right\}#2}

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{\qrlew: Differentially Privacte SQL Query Rewriting}
\author{
    %Authors
    % Authors
    Nicolas Grislain\textsuperscript{\rm 1}
    Paul Roussel\textsuperscript{\rm 1}
    Victoria de Sainte Agathe\textsuperscript{\rm 1}
}
\affiliations{
    %Afiliations
    \textsuperscript{\rm 1}Sarus Technologies\\
    % If you have multiple authors and multiple affiliations
    % use superscripts in text and roman font to identify them.
    % For example,

    % Sunil Issar\textsuperscript{\rm 2},
    % J. Scott Penberthy\textsuperscript{\rm 3},
    % George Ferguson\textsuperscript{\rm 4},
    % Hans Guesgen\textsuperscript{\rm 5}
    % Note that the comma should be placed after the superscript

    1900 Embarcadero Road, Suite 101\\
    Palo Alto, California 94303-3310 USA\\
    % email address must be in roman text type, not monospace or sans serif
    proceedings-questions@aaai.org
%
% See more examples next
}

\iffalse
%Example, Multiple Authors, ->> remove \iffalse,\fi and place them surrounding AAAI title to use it
\title{\qrlew: automatic differential privacy for SQL queries}
\author {
    % Authors
    Nicolas Grislain,
    Paul Roussel,
    Victoria de Sainte Agathe,
}
\affiliations {
    % Affiliations
    ng@sarus.tech, pr@sarus.tech, vdsa@sarus.tech
}
\fi

\begin{document}

\maketitle

\begin{abstract}
AAAI creates proceedings, working notes, and technical reports directly from electronic source furnished by the authors. To ensure that all papers in the publication have a uniform appearance, authors must adhere to the following instructions.
\end{abstract}

\section{Introduction}

In recent years, the importance of safeguarding privacy when dealing with personal data has continuously increased.
Traditional anonymization techniques have proven vulnerable to re-identification, as demonstrated by numerous works \cite{archie2018s, dwork2017exposed, narayanan2008robust, sweeney2013identifying}.
The total cost of data breaches has also significantly increased \cite{ibm2023cost} and governments have introduced stricter data protection laws.
Yet, the collection, sharing, and utilization of data hold the potential to generate significant value across various industries, including healthcare, finance, transportation, and energy distribution.

To realize these benefits while managing privacy risks, researchers have turned to \emph{differential privacy (DP)} \cite{wood2018differential, dwork2014algorithmic}, which has become the gold standard in academia since its introduction by Dwork et al. in 2006 \cite{dwork2006calibrating} due to its provable and automatic privacy guarantees.

Despite the availability of open-source tools, DP adoption remains limited.
One of the reasons for this lack of adoption is the relative complexity of the existing tools considered the utility of the results.
\qrlew{} has been designed to solve these problems by providing the following features:
\begin{description}
    \item[\qrlew{} provides automatic output privacy guarantees] With \qrlew{} a \emph{data owner} can let an analyst (\emph{data practitionner}) with no expertise in privacy protection run arbitrary SQL queries with strong privacy garantees on the output.
    \item[\qrlew{} leverages existing infrastructures] \qrlew{} rewrites a SQL query into a \emph{differentially private} SQL query that can be run on any data-store with a SQL interface from lightweight DB to big-data stores.
This removes the need for a custom execution engine and enables \emph{differentially private analytics with virtually no technical integration}.
    \item[\qrlew{} leverages synthetic data]. Synthetic data are an increasingly popular way of \emph{privatizing} a dataset. Using jointly \emph{differentially private} mechanisms and \emph{differentially private} synthetic data can be a simple, yet powerful, way of managing a privacy budget and reaching better utility-privacy tradeoffs.
\end{description}

% Motivation DP
% Solutions existantes
% Problème non résolu et nécessité de \qrlew

% à développer plus:
% - adaptativité -> utiliser output DP pour tuner DP aval
% - More mechanisms
% - Interconnectivité

\section{Assumptions and Design Goals}

In this work, we assume the \emph{central model of differential privacy} \cite{near2020threat}, where a trusted central organization: Hospital, Insurance Company, Utility Provider, called the \emph{data owner}, collects and stores personal data in a secured database. and whishes to let untrusted \emph{data-practitionners} run SQL queries on its data.
Furthermore, the
\qrlew{} was designed to ease the

\section{General architecture}

In this work, we assume the \emph{central model of differential privacy} \cite{near2020threat}, where a trusted central organization: Hospital, Insurance Company, Utility Provider, called the \emph{data owner}, collects and stores personal data in a secured database. and whishes to let untrusted \emph{data-practitionners} run SQL queries on its data.
Furthermore, the
\qrlew{} was designed to ease the

\section{Paul on compilation}

\section{Privacy algorithms}
\label{sec:privacy_algos}

At this stage, we examine a \texttt{Relation} that takes one or two protected \texttt{Relation} inputs, where the entity to be protected is specified.
To secure the outcome of the SQL query, it is imperative to protect not only the results obtained from aggregation functions but also the grouping keys.
We will briefly describe these two steps in the following section.

\subsubsection{Protecting aggregation results}

The protection of aggregation functions is carried out in three sequential steps. Given that all currently supported aggregations (\texttt{COUNT}, \texttt{SUM}, \texttt{AVG}, \texttt{VARIANCE} \texttt{STDDEV}) can be expressed as compositions of sums, our focus will be on the \texttt{SUM} aggregation. Let's consider the scenario where we aim to compute the sum of a column.

\begin{enumerate}
	\item \textbf{Limit the contribution per user within groups}:
	We represent the contribution of each user by a vector whose each component is the sum of the contributions within one group
    then we calculate its $\ell_2$ norm.
    Subsequently, we constrain the contributions of a specific user by scaling $\textbf{x}$ with a factor chosen to maintain the original observations if the $\ell_2$ norm of the user's observations does not exceed the clipping factor $c$.
    Conversely, if the $\ell_2$ norm surpasses $c$, the $\ell_2$  norm of the rescaled observations is restricted to $c$.
    More technical details can be found in the appendix \ref{sec:limit_contrib_per_user}.

	\item \textbf{Add random noise}:
	The sum of the original data is substituted with the sum of the scaled data with the addition of Gaussian noise. The level of noise is parameterized by the clipping and privacy parameters.

	\item \textbf{Restrict differentially private aggregation}:
	The final operation involves confining the differentially private aggregation within the bounds automatically computed for the $\text{\texttt{SUM}}(\textbf{x})$.
\end{enumerate}

\subsubsection{Protecting grouping keys}
As explained by \citeauthor{wilson2019differentially}, making grouping keys public could result in privacy breaches.
The treatment of grouping keys varies depending on whether the analyst knows them.

\begin{itemize}
	\item \textbf{Public Grouping Keys.}We categorize grouping keys as public when the analyst specifies them in the \texttt{WHERE} clause.
	In this scenario, all user-specified keys must be disclosed, even if they do not exist in the database.
	If a key is absent in the database, differentially private results will include these missing keys, and the corresponding aggregations will be random noise.
	\item \textbf{Revealing Private Keys through $\tau$-Thresholding}
	As introduced by \citeauthor{wilson2019differentially}, tau-thresholding involves releasing keys whose differentially private noise surpasses a threshold determined by privacy parameters.
\end{itemize}

When the SQL query involves both public and private grouping keys, we perform cross joins on the grouping keys obtained through the two algorithms.

\section{Comparison to other systems}

The Google differential-privacy extension for ZetaSQL enables differentially private analysis through SQL tools.
Users can incorporate privacy guarantees by including a privacy clause in their queries, which replaces aggregations with their differentially private equivalent,
limits the number of grouping keys per user, and applies tau-thresholding.
While this framework does not support complex queries with joins or inner subqueries,
it offers a straightforward integration with SQL databases.

Smartnoise SQL is a Python framework, built on the top of Open-DP, for doing SQL analysis with differential privacy guarantees.
The framework is easy of use for non-experts, but it does not support all SQL grammar, and complex queries with joins or subqueries are not supported.
Additionally, the execution of SQL analysis requires a Python post-processing step,
potentially leading to increased execution times.

OpenDP is a Rust library with Python bidings designed for building SQL-like transformations with differential privacy guarantees.
Each part of the code is well documented with mathematical proofs but
its utilization can be challenging for for non experts.

Similarly, Tumult Analytics does not directly handle SQL queries; instead, it utilizes transformations that closely resemble SQL syntax.
While offering support for budgeting various privacy tasks, it is important to note that the analysis must be executed by the data owner.

Chorus is the closest framework to \qrlew, and in the work by \citeauthor{johnson2020chorus},
there is a strong emphasis on conducting all analyses directly within the database.
However, it's worth noting that the code for Chorus is no longer being actively maintained.



\section{Known limitations}

\qrlew{} relies on the random number generator of the SQL engine used. It is usually not a cryptographic noise.

\qrlew{} uses the floating-point numbers of the host SQL engine, therefore our system is liable to the vulnerabilities described in \citeauthor{casacuberta2022widespread}.


\section*{Useful links}
\subsection{PPAI}
Last year papers:
\url{https://aaai-ppai23.github.io/#sp2}
This year program:
\url{https://ppai-workshop.github.io/}

\subsection{Comparable open-source projects}

\begin{itemize}
    \item Paszke et al. 2017 - Automatic differentiation in PyTorch \url{https://openreview.net/pdf?id=BJJsrmfCZ}
    \item Frostig et al. 2018 - Compiling machine learning programs via high-level tracing \url{https://mlsys.org/Conferences/2019/doc/2018/146.pdf}
\end{itemize}

\subsection{Comparable DP SQL papers}

\begin{itemize}
    \item Lessons Learned: Surveying the Practicality of Differential Privacy in the Industry \cite{garrido2022lessons}
    \item Tumult Analytics: a robust, easy-to-use, scalable, and expressive framework for differential privacy \cite{berghel2022tumult}
    \item Differentially Private SQL with Bounded User Contribution \cite{wilson2019differentially}
    \item CHORUS: a Programming Framework for Building Scalable Differential Privacy Mechanisms \cite{johnson2020chorus}
    \item Towards Practical Differential Privacy for SQL Queries \cite{johnson2018towards}
\end{itemize}

\bigskip
\noindent Thank you for reading these instructions carefully. We look forward to receiving your electronic files!

% \bibliography{aaai24}
\bibliography{qrlew}

\appendix
\section{Appendix: Limit the contribution per user within the aggregations}
\label{sec:limit_contrib_per_user}

The observations can be represented as a matrix whose first dimension is the user
and second dimension is the group:

\[ \vphantom{% phantom stuff for correct box dimensions
    \begin{matrix}
    \overbrace{XYZ}^{\mbox{$R$}}\\ \\ \\ \\ \\ \\
    \end{matrix}}%
\begin{pmatrix}
    \coolover{\text{Group 1}}{~~~x_{11}} & \coolover{\text{Group 2}}{~~~x_{12}} & \hdots & \coolover{\text{Group n}}{~~~x_{1n}} \\
    ~~~x_{21} & ~~~x_{22} & \hdots & ~~~x_{2n}  \\
    \vdots & \vdots &  & \vdots  \\
    ~~~x_{m1} & ~~~x_{m2} & \hdots & ~~~x_{mn}
\end{pmatrix}%
\begin{matrix}% matrix for right braces
    \coolrightbrace{x}{\text{User 1}}\\
    \coolrightbrace{x}{\text{User 2}}\\
    \vphantom{\vdots} \\
    \coolrightbrace{x}{\text{User }m}\\
\end{matrix}
\]

The coordinate $x_{ij}$ is the sum of all the observations of user $i$ within the group $j$.


For each user $i$, we compute the scale factor that constrains his contribution to a maximum value of $c$:

\begin{equation}
	s_i = \frac{1}{\max ( 1, \frac{1}{c} \ell_2(x_{i,.}) )} \text{  with  } \ell_2(x_{i,.}) = \sqrt{\sum_j x^2_{ij}}.
\end{equation}

The original data is then rescaled by multiplying each observation by the corresponding user's scale factor.
This process ensures that the $\ell_2$ contribution of each user is restricted to $c$ within the rescaled data.

In our algorithm, the clipping value $c$ is given by:
\begin{equation}
    c = \max ( |\min \textbf{x}|, |\max \textbf{x}|),
\end{equation}
where $\min \textbf{x}$ and $\max \textbf{x}$ are the automatically computed bounds of $\textbf{x}$.

\end{document}
